{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from mnistData2 import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1293161118.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m\u001b[0m\n\u001b[1;33m    model.add(Activation(\"relu\"))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mnist_data = MNIST()\n",
    "x_train, y_train = mnist_data.get_train_set()\n",
    "x_test, y_test = mnist_data.get_test_set()\n",
    "\n",
    "print(f\"Train shape: {x_train.shape}, Test shape: {x_test.shape}\")\n",
    "\n",
    "# Define the DNN\n",
    "model = Sequential()\n",
    "# Conv BLock 1\n",
    "model.add(Conv2D(filters=32, kernel_size=(7, 7), input_shape=(28, 28, 1))) # Jeder der 32 Filter ist 7x7 gro√ü\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Conv BLock 2\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Output Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "# Print the DNN layers\n",
    "model.summary()\n",
    "\n",
    "# Compile the DNN\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train the DNN\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    verbose=1,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test),\n",
    ")\n",
    "\n",
    "# Test the DNN\n",
    "score = model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "print(f\"Test accuracy: {score}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad6c57515631d9bb109eb499b4bb1ec6f506277a5ee28599dfb5ae2805d1ee5a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf_udemy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
